{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "af48bded",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'dlib'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-f0d73853779e>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0margparse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m \u001b[1;32mimport\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m \u001b[1;31m#import imutils\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'dlib'"
     ]
    }
   ],
   "source": [
    "from collections import OrderedDict\n",
    "import numpy as np\n",
    "import cv2\n",
    "import argparse\n",
    "#import dlib\n",
    "#import imutils"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "448aa255",
   "metadata": {},
   "outputs": [],
   "source": [
    "facial_features_cordinates = {}\n",
    "# define a dictionary that maps the indexes of the facial landmarks to specific face r\n",
    "FACIAL_LANDMARKS_INDEXES = OrderedDict([\n",
    "(\"Mouth\", (48, 68)),\n",
    "(\"Right_Eyebrow\", (17, 22)),\n",
    "(\"Left_Eyebrow\", (22, 27)),\n",
    "(\"Right_Eye\", (36, 42)),\n",
    "(\"Left_Eye\", (42, 48)),\n",
    "(\"Nose\", (27, 35)),\n",
    "(\"Jaw\", (0, 17))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdf01966",
   "metadata": {},
   "outputs": [],
   "source": [
    "def shape_to_numpy_array(shape, dtype=\"int\"):\n",
    "# initialize the list of (x, y)-coordinates\n",
    "    coordinates = np.zeros((68, 2), dtype=dtype)\n",
    "# loop over the 68 facial landmarks and convert them\n",
    "# to a 2-tuple of (x, y)-coordinates\n",
    "    for i in range(0, 68):\n",
    "        coordinates[i] = (shape.part(i).x, shape.part(i).y)\n",
    "# return the list of (x, y)-coordinates\n",
    "    return coordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "1bba6771",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_facial_landmarks(image, shape, colors=None, alpha=0.75):\n",
    "# create two copies of the input image -- one for the\n",
    "# overlay and one for the final output image\n",
    "    overlay = image.copy()\n",
    "    output = image.copy()\n",
    "# if the colors list is None, initialize it with a unique\n",
    "# color for each facial landmark region\n",
    "    if colors is None:\n",
    "        colors = [(19, 199, 109), (79, 76, 240), (230, 159, 23), (168, 100, 168), (158, 163, 32), (163, 38, 32), (180, 42, 220)]\n",
    "# loop over the facial landmark regions individually\n",
    "    for (i, name) in enumerate(FACIAL_LANDMARKS_INDEXES.keys()):\n",
    "# grab the (x, y)-coordinates associated with the\n",
    "# face landmark\n",
    "        (j, k) = FACIAL_LANDMARKS_INDEXES[name]\n",
    "        pts = shape[j:k]\n",
    "        facial_features_cordinates[name] = pts\n",
    "# check if are supposed to draw the jawline\n",
    "        if name == \"Jaw\":\n",
    "# since the jawline is a non-enclosed facial region,\n",
    "# just draw lines between the (x, y)-coordinates\n",
    "            for l in range(1, len(pts)):\n",
    "                ptA = tuple(pts[l - 1])\n",
    "                ptB = tuple(pts[l])\n",
    "                cv2.line(overlay, ptA, ptB, colors[i], 2)\n",
    "# otherwise, compute the convex hull of the facial\n",
    "# landmark coordinates points and display it\n",
    "        else:\n",
    "            hull = cv2.convexHull(pts)\n",
    "            cv2.drawContours(overlay, [hull], -1, colors[i], -1)\n",
    "# apply the transparent overlay\n",
    "    cv2.addWeighted(overlay, alpha, output, 1 - alpha, 0, output)\n",
    "# return the output image\n",
    "# print(facial_features_cordinates)\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "02ec1cf1",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'dlib' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-41-c8202b9bf636>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# the facial landmark predictor\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mmodel_path\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'shape_predictor_68_face_landmarks.dat'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mdetector\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_frontal_face_detector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[0mpredictor\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdlib\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape_predictor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'dlib' is not defined"
     ]
    }
   ],
   "source": [
    "# initialize dlib's face detector (HOG-based) and then create\n",
    "# the facial landmark predictor\n",
    "model_path = 'shape_predictor_68_face_landmarks.dat'\n",
    "detector = dlib.get_frontal_face_detector()\n",
    "predictor = dlib.shape_predictor(model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "49a70108",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load the input image, resize it, and convert it to grayscale\n",
    "image_path = 'image.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "#image = imutils.resize(image, width=500)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# detect faces in the grayscale image\n",
    "#rects = detector(gray, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "aea35bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loop over the face detections\n",
    "# from google.colab.patches import cv2_imshow\n",
    "# import cv2\n",
    "# #for (i, rect) in enumerate(rects):\n",
    "# # determine the facial landmarks for the face region, then\n",
    "# # convert the landmark (x, y)-coordinates to a NumPy array\n",
    "#     shape = predictor(gray, rect)\n",
    "#     shape = shape_to_numpy_array(shape)\n",
    "#     output = visualize_facial_landmarks(image, shape)\n",
    "#     img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "#     cv2.imshow(\"test\", output)\n",
    "#     cv2.waitKey(0)\n",
    "#     cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c5e58532",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-23-550e87891ad8>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mnum\u001b[0m \u001b[1;32min\u001b[0m \u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m4\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m5\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"images/image_\"\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnum\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[1;34m\".jpg\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minterpolation\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mINTER_AREA\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mface_cascade\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCascadeClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frontface.xml'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\resize.cpp:4052: error: (-215:Assertion failed) !ssize.empty() in function 'cv::resize'\n"
     ]
    }
   ],
   "source": [
    "faces_array = []\n",
    "grays = {}\n",
    "points = {}\n",
    "images = {}\n",
    "for num in [1, 2, 3, 4, 5]:\n",
    "    image = cv2.imread(\"images/image_\" + str(num) + \".jpg\")\n",
    "    image = cv2.resize(image, (300,300), interpolation = cv2.INTER_AREA)\n",
    "    face_cascade = cv2.CascadeClassifier('frontface.xml')\n",
    "    gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "    faces = face_cascade.detectMultiScale(gray, 1.1, 4)\n",
    "    faces_array.append(faces)\n",
    "    for (x, y, w, h) in faces:\n",
    "        for i in range(x,x+w):\n",
    "            for j in range(y,y+h):\n",
    "                key = \"key_\" + str(num)\n",
    "                points[key] = ([i,j])\n",
    "                images[key] = image\n",
    "                grays[key] = gray\n",
    "            cv2.rectangle(image, (x, y), (x+w, y+h), (255, 0, 0), 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "cf7f2a6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dict_keys([]) dict_keys([]) dict_keys([])\n"
     ]
    }
   ],
   "source": [
    "print(images.keys(), points.keys(), grays.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3731f722",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def averaging_images(key_a, key_b):\n",
    "    for i in range(0,300):\n",
    "        for j in range(0,300):\n",
    "            a=math.pow(grays[key_a][i][j],2)\n",
    "            b=math.pow(grays[key_b][i][j],2)\n",
    "            y=np.add(a,b)\n",
    "            z=math.sqrt(y)\n",
    "            grays[key_b][i][j] = np.divide(z,2).astype(int)\n",
    "    cv2.imshow(\"image\", grays[key_b])\n",
    "    cv2.waitKey(0)\n",
    "    cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "9388a5ed",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'key_1'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-613feef6b58a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0maveraging_images\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"key_1\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"key_2\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m<ipython-input-25-53edfd565736>\u001b[0m in \u001b[0;36maveraging_images\u001b[1;34m(key_a, key_b)\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m             \u001b[0ma\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_a\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      6\u001b[0m             \u001b[0mb\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmath\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrays\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey_b\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mj\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;36m2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0madd\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'key_1'"
     ]
    }
   ],
   "source": [
    "averaging_images(\"key_1\", \"key_2\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "4ce1b13b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_facial_landmarks_change(image, shape, colors=None, alpha=0.75):\n",
    "# create two copies of the input image -- one for the\n",
    "# overlay and one for the final output image\n",
    "    overlay = image.copy()\n",
    "    output = image.copy()\n",
    "# if the colors list is None, initialize it with a unique\n",
    "# color for each facial landmark region\n",
    "    if colors is None:\n",
    "        colors = [(19, 199, 109), (79, 76, 240), (230, 159, 23), (168, 100, 168), (158, 163, 32), (163, 38, 32), (180, 42, 220)]\n",
    "# loop over the facial landmark regions individually\n",
    "    for (i, name) in enumerate(FACIAL_LANDMARKS_INDEXES.keys()):\n",
    "# grab the (x, y)-coordinates associated with the\n",
    "# face landmark\n",
    "        (j, k) = FACIAL_LANDMARKS_INDEXES[name]\n",
    "        pts = shape[j:k]\n",
    "        facial_features_cordinates[name] = pts\n",
    "# check if are supposed to draw the jawline\n",
    "# return the output image\n",
    "# print(facial_features_cordinates)\n",
    "    return output,facial_features_cordinates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a4d6f754",
   "metadata": {},
   "outputs": [
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-29-a1d121db3faf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;31m#image = imutils.resize(image, width=300,height=300)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m \u001b[0mgray\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;31m# detect faces in the grayscale image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[0mrects\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdetector\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgray\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.5) D:\\a\\opencv-python\\opencv-python\\opencv\\modules\\imgproc\\src\\color.cpp:182: error: (-215:Assertion failed) !_src.empty() in function 'cv::cvtColor'\n"
     ]
    }
   ],
   "source": [
    "image_path = 'images.jpg'\n",
    "image = cv2.imread(image_path)\n",
    "#image = imutils.resize(image, width=300,height=300)\n",
    "gray = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)\n",
    "# detect faces in the grayscale image\n",
    "rects = detector(gray, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "40b69ec5",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-30-fe14c3fb184e>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-30-fe14c3fb184e>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    shape = predictor(gray, rect)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "for (i, rect) in enumerate(rects):\n",
    "# determine the facial landmarks for the face region, then\n",
    "# convert the landmark (x, y)-coordinates to a NumPy array\n",
    "shape = predictor(gray, rect)\n",
    "shape = shape_to_numpy_array(shape)\n",
    "image_main, point_68_main = visualize_facial_landmarks_change(image, shape)\n",
    "img = cv2.imread(image_path, cv2.IMREAD_UNCHANGED)\n",
    "cv2.imshow(\"output\", image_main)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "bfe04eef",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'imutils' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-31-f06639c9aa54>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0mimage_path_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;34m'images/image_2.jpg'\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mimage_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimread\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_path_2\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mimage_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mimutils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mwidth\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mheight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mgray_2\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_2\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# detect faces in the grayscale image\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'imutils' is not defined"
     ]
    }
   ],
   "source": [
    "image_path_2 = 'images/image_2.jpg'\n",
    "image_2 = cv2.imread(image_path_2)\n",
    "image_2 = imutils.resize(image_2, width=300,height=300)\n",
    "gray_2 = cv2.cvtColor(image_2, cv2.COLOR_BGR2GRAY)\n",
    "# detect faces in the grayscale image\n",
    "rects_2 = detector(gray_2, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "96c6053b",
   "metadata": {},
   "outputs": [
    {
     "ename": "IndentationError",
     "evalue": "expected an indented block (<ipython-input-32-58bbb5e952d2>, line 5)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;36m  File \u001b[1;32m\"<ipython-input-32-58bbb5e952d2>\"\u001b[1;36m, line \u001b[1;32m5\u001b[0m\n\u001b[1;33m    shape_2 = predictor(gray_2,rect)\u001b[0m\n\u001b[1;37m    ^\u001b[0m\n\u001b[1;31mIndentationError\u001b[0m\u001b[1;31m:\u001b[0m expected an indented block\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "for (i, rect) in enumerate(rects_2):\n",
    "# determine the facial landmarks for the face region, then\n",
    "# convert the landmark (x, y)-coordinates to a NumPy array\n",
    "shape_2 = predictor(gray_2,rect)\n",
    "shape_2 = shape_to_numpy_array(shape_2)\n",
    "image_change,point_68 = visualize_facial_landmarks_change(image_2, shape_2)\n",
    "img = cv2.imread(image_path_2, cv2.IMREAD_UNCHANGED)\n",
    "cv2.imshow(\"image_change\", image_change)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "57260bec",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_over68_points(point_68,point_68_main,image_change,image_main):\n",
    "    for i in range(0,300):\n",
    "        for j in range(0,300):\n",
    "            a=image_change[i][j]\n",
    "            b=image_main[i][j]\n",
    "            y=a+b\n",
    "            z=math.sqrt(y)\n",
    "            image_change[i][j] = np.multiply(5,np.divide(z,2)).astype(int)\n",
    "    return image_change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "ea5d90ab",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'image_change' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-888375a3875c>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mgray_image_change\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_change\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mgray_imaage_main\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcvtColor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mimage_main\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCOLOR_BGR2GRAY\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0maveraged_image\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0maveraging_over68_points\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpoint_68\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mpoint_68_main\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mgray_image_change\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'image_change' is not defined"
     ]
    }
   ],
   "source": [
    "gray_image_change=cv2.cvtColor(image_change, cv2.COLOR_BGR2GRAY)\n",
    "gray_imaage_main=cv2.cvtColor(image_main, cv2.COLOR_BGR2GRAY)\n",
    "averaged_image =averaging_over68_points(point_68,point_68_main,gray_image_change)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "3d21ef89",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'averaged_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-36-3c8a375a79c6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"averaged_image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maveraged_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'averaged_image' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"averaged_image\", averaged_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "5236232d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_over68_points(point_68,point_68_main, im, image_main):\n",
    "    for i in range(0,300):\n",
    "        for j in range(0,300):\n",
    "            z = np.multiply(2,np.divide(im[i][j],5)).astype(int)\n",
    "            y= math.pow(z,2)\n",
    "            b=image_main[i][j]\n",
    "            a=y-b\n",
    "            im[i][j]=a\n",
    "    return im"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "43ad01b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#recovered_image = recover_over68_points(point_68,point_68_main, averaged_image, gray_i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "8012a2e8",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'recovered_image' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-f7a1828eac88>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"recovered_image\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrecovered_image\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwaitKey\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdestroyAllWindows\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'recovered_image' is not defined"
     ]
    }
   ],
   "source": [
    "cv2.imshow(\"recovered_image\", recovered_image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bd8d8b7",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
